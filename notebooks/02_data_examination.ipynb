{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02. Data Examination\n",
    "\n",
    "This module shows the types of data and pipelines that are in the [HuBMAP Data Portal](https://portal.hubmapconsortium.org/). It shows how to retrieve metadata, and how to filter datasets based on this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Types\n",
    "There are many dataset types. On the [Datasets page](https://portal.hubmapconsortium.org/search?entity_type[0]=Dataset), you see a filter on the left with many dataset types.\n",
    "\n",
    "There are unprocessed and processed datasets in the Portal. Click the collapsing arrow next to 'CODEX'. It shows two subsections, 'CODEX' and 'CODEX [Cytokit + SPRM]'. The second subsection ('CODEX [Cytokit + SPRM]') are the processed datasets. One of these is [HBM926.SHNZ.594](https://portal.hubmapconsortium.org/browse/dataset/69c70762689b20308bb049ac49653342). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring a Dataset on the Portal page.\n",
    "Let's explore the detail page of [HBM926.SHNZ.594](https://portal.hubmapconsortium.org/browse/dataset/69c70762689b20308bb049ac49653342).\n",
    "\n",
    "#### Primary and processed datasets\n",
    "HBM926.SHNZ.594 is a processed or derived dataset. A processed dataset is created by running a primary dataset through various pipelines. The detail page shows both the primary and any processed datasets.\n",
    "\n",
    "##### Primary dataset information & metadata\n",
    "- The information about primary dataset is shown on top. Here we can see the primary dataset that this processed dataset is derived from.\n",
    "- Metadata: In this section, we can find a few key metadata values about the assay and the donor.\n",
    "\n",
    "##### Processed dataset information\n",
    "Under the processed dataset, there are a few sections: \n",
    "- Summary: This section contains some basic information about this dataset.\n",
    "- Visualization: A Vitessce Visualization is automatically rendered for each dataset. Explore the different panels to get a gist of the data in the dataset.\n",
    "- Files: The Data Products tab lists a few of the available files that are available in this dataset that are often used. The File Browser tab lists all available files.\n",
    "- Analysis Details & Protocols: Here, the analyses pipelines are listed. These are the ingest pipelines that the primary dataset is ingested into.\n",
    "\n",
    "##### Other sections\n",
    "Now let's examine the information below the derived dataset.\n",
    "- Bulk Data Transfer: In this section, we can find links to the Globus directories for the primary and processed datasets.\n",
    "- Provenance: Here we see a graphical overview of how the datasets are related.\n",
    "- Attribution: This section lists the individuals who provided this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring a Dataset through the search API.\n",
    "We can also retrieve most of this information programmatically.\n",
    "\n",
    "Each dataset is identified with two IDs. One is the HuBMAP ID, in the form of HBMXXX.XXXX.XXX, in our case _HBM926.SHNZ.594_. The other is the UUID, in our case _69c70762689b20308bb049ac49653342_. The UUID is used in the backend. When refering to datasets in the Workspaces, the UUID is also used. There is a HuBMAP template helper package that has a method to retrieve a mapping for UUIDs to HuBMAP IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy pandas requests wheel hubmap_template_helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required packages\n",
    "import requests\n",
    "import json\n",
    "\n",
    "from hubmap_template_helper import uuids as hth_uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the UUID of our dataset\n",
    "uuids = ['69c70762689b20308bb049ac49653342']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HuBMAP IDs are more readable than UUIDs, so we can convert these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This method retrieves a mapping between the UUID and HuBMAP ID.\n",
    "# This uses a post request to https://portal.hubmapconsortium.org/metadata/v0/datasets.tsv\n",
    "\n",
    "uuid_to_hubmap = hth_uuids.get_uuid_to_hubmap_mapping(uuids)\n",
    "uuid_to_hubmap[uuids[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Search API, we can then find information about processed datasets. For this, we send a POST request to the Search API. In this, we add our query. To find metadata of our dataset, we add the UUID of the dataset in our query. We can also add a size of returned elements.\n",
    "\n",
    "> Note: the search API only retrieves this metadata for processed datasets, not for primary datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_api = \"https://search.api.hubmapconsortium.org/v3/portal/search\"\n",
    "\n",
    "hits = json.loads(\n",
    "    requests.post(\n",
    "        search_api,\n",
    "        json={\n",
    "            \"size\": 10000,  # To make sure the list is not truncted, set this high.\n",
    "            \"query\": {\"ids\": {\"values\": uuids}},\n",
    "        },\n",
    "    ).text\n",
    ")[\"hits\"][\"hits\"]\n",
    "\n",
    "hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that that is a lot of information, more than is available in the Portal! Instead of requesting all information, we can also search for specific things, such as the files and data types that a dataset contains. Here, we add an extra field to specify what information we want returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = json.loads(\n",
    "    requests.post(\n",
    "        search_api,\n",
    "        json={\n",
    "            'size': 10000,\n",
    "            'query': {'ids': {'values': uuids}},\n",
    "            '_source': ['files', 'data_types']\n",
    "        }, \n",
    "    ).text\n",
    ")['hits']['hits']\n",
    "\n",
    "hits[0]['_source']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use ElasticSearch queries to find specific datasets. Instead of adding UUIDs to find information on, we can specify the type of dataset that we are interested in, such as a datasets with CODEX data type and ome.tiff files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show how to do a filter\n",
    "\n",
    "hits = json.loads(\n",
    "    requests.post(\n",
    "        search_api,\n",
    "        json={\n",
    "            \"size\": 100,\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"must\": [\n",
    "                        {\n",
    "                            \"match\": {\n",
    "                                \"files.rel_path\": \"ome.tiff\" # find entities with an ome.tiff file\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"match\": {\n",
    "                                \"assay_display_name\": \"CODEX\" # find entities with CODEX data types\n",
    "                            }\n",
    "                        }\n",
    "                    ],\n",
    "                    \"filter\": [\n",
    "                        {\n",
    "                            \"bool\": {\n",
    "                                \"must_not\": {\n",
    "                                    \"exists\": {\n",
    "                                        \"field\": \"next_revision_uuid\" # this is an artifact of the Portal, filtering out some old data.\n",
    "                                    }\n",
    "                                }\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"term\": {\n",
    "                                \"entity_type.keyword\": \"Dataset\" # find entities that are datasets\n",
    "                            }\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            \"_source\": [\n",
    "                \"hubmap_id\",\n",
    "                \"group_uuid\",\n",
    "                \"uuid\",\n",
    "                \"entity_type\",\n",
    "                \"assay_display_name\",\n",
    "                \"donor.mapped_metadata.sex\" # use dot notation to get specific fields\n",
    "            ]\n",
    "        }, \n",
    "    ).text\n",
    ")['hits']['hits']\n",
    "\n",
    "hits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it for yourself!\n",
    "Try to examine some data. Perhaps you want to find specific datasets. Or you want to retrieve information about specific datasets. Feel free to use our daily office hours to ask questions about this as well!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
